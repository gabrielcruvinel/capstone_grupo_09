{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "125cd393-8635-4245-996a-e25bb3948a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a73a04e1-e66d-49ba-8612-d1b019c55157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "from faker import Faker\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "import decimal\n",
    "\n",
    "# --- SETUP INICIAL ---\n",
    "fake = Faker('pt_BR')\n",
    "\n",
    "# --- 1. DEFINIÇÃO DOS SCHEMAS ---\n",
    "\n",
    "schema_cliente = StructType([\n",
    "    StructField(\"id_cli\", IntegerType(), False),\n",
    "    StructField(\"nm_cli\", StringType(), True),\n",
    "    StructField(\"dt_nsct_cli\", DateType(), True),\n",
    "    StructField(\"email_cli\", StringType(), True),\n",
    "    StructField(\"tel_cli\", StringType(), True),\n",
    "    StructField(\"end_cli\", StringType(), True),\n",
    "    StructField(\"munic_cli\", StringType(), True),\n",
    "    StructField(\"uf_cli\", StringType(), True),\n",
    "    StructField(\"cep_cli\", StringType(), True),\n",
    "    StructField(\"rend_cli\", DecimalType(10, 2), True),\n",
    "    StructField(\"profi_cli\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema_conta = StructType([\n",
    "    StructField(\"id_conta\", StringType(), False),      # UUID ou Hash\n",
    "    StructField(\"id_cli\", IntegerType(), False),       # FK para tb_cliente\n",
    "    StructField(\"num_conta\", StringType(), True),      # Número da conta\n",
    "    StructField(\"cod_agencia\", StringType(), True),    # Código da agência\n",
    "    StructField(\"vlr_saldo_atual\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_limite_esp\", DecimalType(18, 2), True),\n",
    "    StructField(\"status_conta\", StringType(), True),   # Ativa, Bloqueada, Encerrada\n",
    "    StructField(\"dt_abertura\", DateType(), True),\n",
    "    StructField(\"ind_cartao_deb\", BooleanType(), True) # True/False\n",
    "])\n",
    "\n",
    "schema_cartao = StructType([\n",
    "    StructField(\"id_cartao\", StringType(), False),\n",
    "    StructField(\"id_conta\", StringType(), False),\n",
    "    StructField(\"bandeira_cartao\", StringType(), True),\n",
    "    StructField(\"categoria_cartao\", StringType(), True),\n",
    "    StructField(\"num_cartao_final\", StringType(), True),\n",
    "    StructField(\"dt_validade\", StringType(), True),\n",
    "    StructField(\"vlr_limite_tot\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_limite_disp\", DecimalType(18, 2), True),\n",
    "    StructField(\"dia_vencimento\", IntegerType(), True),\n",
    "    StructField(\"status_cartao\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema_fatura = StructType([\n",
    "    StructField(\"id_fatura\", StringType(), False),\n",
    "    StructField(\"id_cartao\", StringType(), False),\n",
    "    StructField(\"mes_ref\", StringType(), True),\n",
    "    StructField(\"dt_fechamento\", DateType(), True),\n",
    "    StructField(\"dt_vencimento\", DateType(), True),\n",
    "    StructField(\"vlr_compras_mes\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_saldo_anterior\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_encargos_totais\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_ajustes_creditos\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_total_fatura\", DecimalType(18, 2), True),\n",
    "    StructField(\"vlr_minimo\", DecimalType(18, 2), True),\n",
    "    StructField(\"status_fatura\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "schema_extrato = StructType([\n",
    "    StructField(\"id_movimentacao\", StringType(), False),\n",
    "    StructField(\"id_conta\", StringType(), False),\n",
    "    StructField(\"ts_movimentacao\", TimestampType(), True),\n",
    "    StructField(\"dt_contabil\", DateType(), True),\n",
    "    StructField(\"vlr_transacao\", DecimalType(18, 2), True),\n",
    "    StructField(\"tp_operacao\", StringType(), True),\n",
    "    StructField(\"ds_historico\", StringType(), True),\n",
    "    StructField(\"vlr_saldo_pos_mov\", DecimalType(18, 2), True),\n",
    "    StructField(\"tp_instrumento\", StringType(), True),\n",
    "    StructField(\"id_transacao_ref\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema_pagamento = StructType([\n",
    "    StructField(\"id_pagamento\", StringType(), False),\n",
    "    StructField(\"id_fatura\", StringType(), False),\n",
    "    StructField(\"ts_pagamento\", TimestampType(), True),\n",
    "    StructField(\"dt_liquidacao\", DateType(), True),\n",
    "    StructField(\"vlr_pago\", DoubleType(), True),\n",
    "    StructField(\"meio_pagamento\", StringType(), True),\n",
    "    StructField(\"tp_pagamento\", StringType(), True),\n",
    "    StructField(\"ind_atraso\", BooleanType(), True),\n",
    "    StructField(\"id_autenticacao\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema_transacoes_cartao = StructType([\n",
    "    StructField(\"id_transacao\", StringType(), False),\n",
    "    StructField(\"id_cartao\", StringType(), False),\n",
    "    StructField(\"ts_transacao\", TimestampType(), True),\n",
    "    StructField(\"vlr_transacao\", DecimalType(18, 2), True),\n",
    "    StructField(\"nm_estabelecimento\", StringType(), True),\n",
    "    StructField(\"categoria_trans\", StringType(), True),\n",
    "    StructField(\"qtde_parcelas\", IntegerType(), True),\n",
    "    StructField(\"num_parcela\", IntegerType(), True),\n",
    "    StructField(\"ind_contato\", BooleanType(), True),\n",
    "    StructField(\"status_transacao\", StringType(), True)\n",
    "])\n",
    "\n",
    "#2 --- Funcoes \n",
    "def gerar_dados_clientes(qtd_registros=10):\n",
    "\n",
    "    dados = []\n",
    "    \n",
    "    for i in range(1, qtd_registros + 1):\n",
    "        registro = (\n",
    "            i,                                      # id_cli\n",
    "            fake.name(),                            # nm_cli\n",
    "            fake.date_of_birth(minimum_age=18),     # dt_nsct_cli\n",
    "            fake.email(),                           # email_cli\n",
    "            fake.phone_number(),                    # tel_cli\n",
    "            fake.street_address(),                  # end_cli\n",
    "            fake.city(),                            # munic_cli\n",
    "            fake.state_abbr(),                      # uf_cli\n",
    "            fake.postcode().replace(\"-\", \"\"),       # cep_cli\n",
    "            decimal.Decimal(f\"{random.uniform(1500, 30000):.2f}\"),\n",
    "            fake.job()                              # profi_cli\n",
    "        )\n",
    "        dados.append(registro)\n",
    "    \n",
    "    return spark.createDataFrame(dados, schema=schema_cliente)\n",
    "\n",
    "def gerar_dados_contas(lista_id_clientes, qtd_por_cliente=1):\n",
    "\n",
    "    dados_contas = []\n",
    "    \n",
    "    status_opcoes = ['ATIVA', 'BLOQUEADA', 'INATIVA']\n",
    "    \n",
    "    for id_cliente in lista_id_clientes:\n",
    "        for _ in range(qtd_por_cliente):\n",
    "                    \n",
    "            saldo = decimal.Decimal(f\"{random.uniform(-500, 50000):.2f}\")\n",
    "            limite = decimal.Decimal(random.choice([1000, 2000, 5000, 10000]))\n",
    "            \n",
    "            registro = (\n",
    "                str(uuid.uuid4()),                  # id_conta (Gerando um UUID único)\n",
    "                id_cliente,                         # id_cli (FK)\n",
    "                str(fake.random_number(digits=8)),  # num_conta\n",
    "                str(fake.random_number(digits=4)),  # cod_agencia\n",
    "                saldo,                              # vlr_saldo_atual\n",
    "                limite,                             # vlr_limite_esp\n",
    "                random.choice(status_opcoes),       # status_conta\n",
    "                fake.date_between(start_date='-10y', end_date='today'), # dt_abertura\n",
    "                random.choice([True, False])        # ind_cartao_deb\n",
    "            )\n",
    "            dados_contas.append(registro)\n",
    "    \n",
    "    return spark.createDataFrame(dados_contas, schema=schema_conta)\n",
    "\n",
    "\n",
    "def gerar_dados_cartoes(lista_id_contas, qtd_por_conta=1):\n",
    "\n",
    "    dados_cartoes = []\n",
    "    \n",
    "    bandeiras = ['VISA', 'MASTERCARD', 'ELO', 'AMEX']\n",
    "    categorias = ['BASIC', 'GOLD', 'PLATINUM', 'BLACK', 'INFINITE']\n",
    "    status_list = ['ATIVO', 'BLOQUEADO', 'CANCELADO', 'AGUARDANDO ATIVAÇÃO']\n",
    "    # Definimos a precisão de 2 casas decimais (financeiro)\n",
    "    TWO_PLACES = Decimal(\"0.01\")\n",
    "\n",
    "    for id_conta in lista_id_contas:\n",
    "        for _ in range(qtd_por_conta):\n",
    "            # 1. Gerar e arredondar o limite total\n",
    "            limite_total = Decimal(str(random.uniform(1000, 50000))).quantize(TWO_PLACES, rounding=ROUND_HALF_UP)\n",
    "            \n",
    "            # 2. Gerar o multiplicador\n",
    "            multiplicador = Decimal(str(random.uniform(0.1, 1.0)))\n",
    "            \n",
    "            # 3. Calcular o disponível e ARREDONDAR IMEDIATAMENTE\n",
    "            limite_disp = (limite_total * multiplicador).quantize(TWO_PLACES, rounding=ROUND_HALF_UP)\n",
    "            \n",
    "            registro = (\n",
    "                str(uuid.uuid4()),\n",
    "                id_conta,\n",
    "                random.choice(bandeiras),\n",
    "                random.choice(categorias),\n",
    "                str(random.randint(1000, 9999)),\n",
    "                fake.credit_card_expire(),\n",
    "                limite_total,      # Agora garantido com 2 casas\n",
    "                limite_disp,       # Agora garantido com 2 casas\n",
    "                random.randint(1, 28),\n",
    "                random.choice(status_list)\n",
    "            )\n",
    "            dados_cartoes.append(registro)\n",
    "            \n",
    "    return spark.createDataFrame(dados_cartoes, schema=schema_cartao)\n",
    "\n",
    "def gerar_dados_faturas(lista_id_cartoes):\n",
    "    dados_faturas = []\n",
    "    status_opcoes = ['ABERTA', 'FECHADA', 'PAGA', 'PAGAMENTO_PARCIAL', 'ATRASADA']\n",
    "    \n",
    "    # Constantes para precisão\n",
    "    PRECISAO = Decimal(\"0.01\")\n",
    "    TAXA_ENCARGOS = Decimal(\"0.15\")\n",
    "    TAXA_MINIMO = Decimal(\"0.15\")\n",
    "    \n",
    "    for id_cartao in lista_id_cartoes:\n",
    "        # 1. Converter inputs iniciais e arredondar\n",
    "        compras = Decimal(str(random.uniform(100, 8000))).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "        anterior = Decimal(str(random.choice([0, 0, 0, 500, 1200]))).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "        \n",
    "        # 2. Cálculos (agora apenas entre Decimals)\n",
    "        encargos = (anterior * TAXA_ENCARGOS).quantize(PRECISAO, rounding=ROUND_HALF_UP) if anterior > 0 else Decimal(\"0.00\")\n",
    "        ajustes = Decimal(str(random.choice([0, 0, 50, 100]))).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "        \n",
    "        total = (compras + anterior + encargos) - ajustes\n",
    "        minimo = (total * TAXA_MINIMO).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "        \n",
    "        vencimento = fake.date_this_year()\n",
    "        fechamento = vencimento - timedelta(days=10)\n",
    "        \n",
    "        registro = (\n",
    "            str(uuid.uuid4()),\n",
    "            id_cartao,\n",
    "            vencimento.strftime(\"%Y-%m\"),\n",
    "            fechamento,\n",
    "            vencimento,\n",
    "            compras,\n",
    "            anterior,\n",
    "            encargos,\n",
    "            ajustes,\n",
    "            total,\n",
    "            minimo,\n",
    "            random.choice(status_opcoes)\n",
    "        )\n",
    "        dados_faturas.append(registro)\n",
    "            \n",
    "    return spark.createDataFrame(dados_faturas, schema=schema_fatura)\n",
    "\n",
    "def gerar_dados_extrato(lista_id_contas, qtd_mov_por_conta=5):\n",
    "    dados_extrato = []\n",
    "    \n",
    "    # Define a escala financeira (2 casas decimais)\n",
    "    PRECISAO = Decimal(\"0.01\")\n",
    "    \n",
    "    operacoes = [\n",
    "        ('CREDITO', 'PIX Recebido', 'PIX'),\n",
    "        ('DEBITO', 'Compra no Cartão', 'CARTAO'),\n",
    "        ('DEBITO', 'Pagamento de Boleto', 'BOLETO'),\n",
    "        ('CREDITO', 'Transferência Recebida', 'TED'),\n",
    "        ('DEBITO', 'Saque Eletrônico', 'SAQUE')\n",
    "    ]\n",
    "    \n",
    "    for id_conta in lista_id_contas:\n",
    "        # 1. Já inicia o saldo com 2 casas decimais\n",
    "        saldo_simulado = Decimal(str(random.uniform(1000, 5000))).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "        for _ in range(qtd_mov_por_conta):\n",
    "            tp_op, ds, inst = random.choice(operacoes)\n",
    "            # 2. Garante que o valor da movimentação tenha 2 casas decimais\n",
    "            valor = Decimal(str(random.uniform(10, 500))).quantize(PRECISAO, rounding=ROUND_HALF_UP)\n",
    "            if tp_op == 'DEBITO':\n",
    "                saldo_simulado -= valor\n",
    "            else:\n",
    "                saldo_simulado += valor    \n",
    "            ts = fake.date_time_between(start_date='-30d', end_date='now')\n",
    "            registro = (\n",
    "                str(uuid.uuid4()),\n",
    "                id_conta,\n",
    "                ts,\n",
    "                ts.date(),\n",
    "                valor,              # Agora seguro para o Spark\n",
    "                tp_op,\n",
    "                ds,\n",
    "                saldo_simulado,     # Agora seguro para o Spark\n",
    "                inst,\n",
    "                str(uuid.uuid4())\n",
    "            )\n",
    "            dados_extrato.append(registro)\n",
    "    return spark.createDataFrame(dados_extrato, schema=schema_extrato)\n",
    "\n",
    "def gerar_dados_pagamentos(df_faturas):\n",
    "    dados_pagamentos = []\n",
    "    \n",
    "    # Coletamos os dados necessários das faturas para gerar pagamentos realistas\n",
    "    faturas = df_faturas.select(\"id_fatura\", \"vlr_total_fatura\", \"dt_vencimento\").collect()\n",
    "    \n",
    "    meios = ['PIX', 'BOLETO', 'DEBITO_EM_CONTA', 'LOTERICA']\n",
    "    tipos = ['TOTAL', 'PARCIAL', 'MINIMO']\n",
    "    \n",
    "    for fatura in faturas:\n",
    "        # Simula se o pagamento foi feito no dia ou com variação\n",
    "        dias_variacao = random.randint(-5, 5)\n",
    "        data_pagamento_ts = fake.date_time_between_dates(\n",
    "            datetime_start=fatura.dt_vencimento - timedelta(days=10),\n",
    "            datetime_end=fatura.dt_vencimento + timedelta(days=5)\n",
    "        )\n",
    "        \n",
    "        vlr_pago = float(fatura.vlr_total_fatura)\n",
    "        tp_pg = 'TOTAL'\n",
    "        \n",
    "        # Simulação ocasional de pagamento parcial\n",
    "        if random.random() < 0.2:\n",
    "            vlr_pago = vlr_pago * random.uniform(0.2, 0.9)\n",
    "            tp_pg = 'PARCIAL'\n",
    "\n",
    "        atraso = data_pagamento_ts.date() > fatura.dt_vencimento\n",
    "        \n",
    "        registro = (\n",
    "            str(uuid.uuid4()),\n",
    "            fatura.id_fatura,\n",
    "            data_pagamento_ts,\n",
    "            data_pagamento_ts.date() + timedelta(days=1), # Liquidação D+1\n",
    "            vlr_pago,\n",
    "            random.choice(meios),\n",
    "            tp_pg,\n",
    "            atraso,\n",
    "            str(uuid.uuid4()).upper().replace(\"-\", \"\")[:20] # ID Autenticação\n",
    "        )\n",
    "        dados_pagamentos.append(registro)\n",
    "            \n",
    "    return spark.createDataFrame(dados_pagamentos, schema=schema_pagamento)\n",
    "\n",
    "def gerar_dados_transacoes_cartao(lista_id_cartoes, qtd_trans_por_cartao=10):\n",
    "    dados_transacoes = []\n",
    "    \n",
    "    categorias = ['ALIMENTAÇÃO', 'LAZER', 'TRANSPORTE', 'SAÚDE', 'EDUCAÇÃO', 'SERVIÇOS', 'VESTUÁRIO']\n",
    "    estabelecimentos = ['Mercado Central', 'Posto Ipiranga', 'Netflix', 'Amazon', 'Farmácia Preço Baixo', 'Restaurante Sabor', 'Uber']\n",
    "    status_opcoes = ['APROVADA', 'APROVADA', 'APROVADA', 'NEGADA', 'ESTORNADA']\n",
    "    \n",
    "    for id_cartao in lista_id_cartoes:\n",
    "        for _ in range(qtd_trans_por_cartao):\n",
    "            parcelas = random.choice([1, 1, 1, 2, 3, 10, 12])\n",
    "            vlr_total = random.uniform(5.0, 2500.0)\n",
    "            \n",
    "            # Cálculo do valor da parcela convertido para Decimal\n",
    "            vlr_parcela = decimal.Decimal(vlr_total / parcelas).quantize(decimal.Decimal('0.00'))\n",
    "            \n",
    "            num_parc = 1 if parcelas == 1 else random.randint(1, parcelas)\n",
    "            \n",
    "            registro = (\n",
    "                str(uuid.uuid4()),\n",
    "                id_cartao,\n",
    "                fake.date_time_between(start_date='-60d', end_date='now'),\n",
    "                vlr_parcela, # Agora é um objeto decimal.Decimal\n",
    "                random.choice(estabelecimentos),\n",
    "                random.choice(categorias),\n",
    "                parcelas,\n",
    "                num_parc,\n",
    "                random.choice([True, False]),\n",
    "                random.choice(status_opcoes)\n",
    "            )\n",
    "            dados_transacoes.append(registro)\n",
    "            \n",
    "    return spark.createDataFrame(dados_transacoes, schema=schema_transacoes_cartao)\n",
    "\n",
    "\n",
    "# 3 - Insert de dados\n",
    "def inserir_dados_delta_table(df, workspace, schema, nome_tabela, modo=\"append\"):\n",
    "    try:\n",
    "        df.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{workspace}.{schema}.{nome_tabela}\")\n",
    "        print(f\"Sucesso: Dados inseridos na tabela '{nome_tabela}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao inserir dados: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1af1cbff-4bac-4028-9fa0-483a54fed6f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Geramos 10 clientes\n",
    "df_clientes = gerar_dados_clientes(10)\n",
    "\n",
    "# 2. Extraímos a lista de IDs de clientes para usar como FK\n",
    "ids_clientes = [row.id_cli for row in df_clientes.select(\"id_cli\").collect()]\n",
    "\n",
    "# 3. Geramos as contas vinculadas a esses IDs\n",
    "df_contas = gerar_dados_contas(ids_clientes, qtd_por_cliente=1)\n",
    "\n",
    "#4. Extrai ID da conta\n",
    "ids_contas = [r.id_conta for r in df_contas.select(\"id_conta\").collect()]\n",
    "\n",
    "#5. Geramos os cartoes\n",
    "df_cartoes = gerar_dados_cartoes(ids_contas)\n",
    "\n",
    "#6. geramos os ids dos cartoes\n",
    "ids_cartoes = [r.id_cartao for r in df_cartoes.select(\"id_cartao\").collect()]\n",
    "\n",
    "#7. geramos as faturas dos cartoes\n",
    "df_faturas = gerar_dados_faturas(ids_cartoes)\n",
    "\n",
    "#8. geramos as pagamentos de faturas do cartao\n",
    "df_faturas_pagamento = gerar_dados_pagamentos(df_faturas)\n",
    "\n",
    "#9. De posse dos ids das contas, geramos o extrato do mesmo\n",
    "df_extrato = gerar_dados_extrato(ids_contas)\n",
    "\n",
    "#10. Geramos a base de transacoes de cartao\n",
    "df_transacoes = gerar_dados_transacoes_cartao(ids_cartoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52902ca8-3a4e-41a8-84e8-91be0f83a8fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inserir_dados_delta_table(df_clientes, 'capstonebricks', 'bronze', 'tb_cliente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09cb6f8c-daba-4860-ae3b-ea0522a618b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inserir_dados_delta_table(df_clientes, 'capstonebricks', 'bronze', 'tb_cliente', 'overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c3ac16-4a9d-4f2d-ad21-465d9c6730ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inserir_dados_delta_table(df_contas, 'capstonebricks', 'bronze', 'tb_conta')\n",
    "inserir_dados_delta_table(df_cartoes, 'capstonebricks', 'bronze', 'tb_cartao')\n",
    "inserir_dados_delta_table(df_faturas, 'capstonebricks', 'bronze', 'tb_fatura_cartao')\n",
    "inserir_dados_delta_table(df_faturas_pagamento, 'capstonebricks', 'bronze', 'tb_pagamento_fatura')\n",
    "inserir_dados_delta_table(df_extrato, 'capstonebricks', 'bronze', 'tb_extrato')\n",
    "inserir_dados_delta_table(df_transacoes, 'capstonebricks', 'bronze', 'tb_transacoes_cartao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "172e317b-b247-4149-ae08-45900d32b474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b187c2db-c8b9-4227-b97c-0b6a7e383e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa52e21-005b-44a0-8d0f-6a099d7525ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03655396-c24d-4d1f-9688-dd083c21c914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "camada_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
